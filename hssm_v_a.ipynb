{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62647dec",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea94f1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javierrojas/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting PyTensor floatX type to float32.\n",
      "Setting \"jax_enable_x64\" to False. If this is not intended, please set `jax` to False.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import jax\n",
    "import numpyro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import hssm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "hssm.set_floatX(\"float32\")\n",
    "numpyro.set_host_device_count(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f932cff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('data_wt_exp5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75b439b",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d977a499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsitute_values_sequential(data,varname,new_values):\n",
    "  unique_values = sorted(data[varname].unique())\n",
    "  substitutions = {val: new_val for val, new_val in zip(unique_values,new_values)}\n",
    "  return  data[varname].replace(substitutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f7c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_z(x):\n",
    "    x = np.asarray(x, float)\n",
    "    med = np.median(x)\n",
    "    mad = np.median(np.abs(x - med))\n",
    "    return 0.6745 * (x - med) / (mad if mad>0 else np.finfo(float).eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ef5573",
   "metadata": {},
   "source": [
    "### Data Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7975fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_raw.copy()\n",
    "\n",
    "## stim side l/r (-1/1)\n",
    "data['stim_side'] =  np.sign(data['stim'])\n",
    "\n",
    "## Desirability side l/r (-1/1)\n",
    "data['des_side'] = np.sign(data['stim'])*data['desirability']\n",
    "\n",
    "## Stim evidence: low vs high (0/1)\n",
    "data['stim_easy'] = subsitute_values_sequential(data,'stim_strength',[0.25,.5,0.75,1])\n",
    "\n",
    "## Incentive: low vs high (0/1)\n",
    "data['incentive'] = subsitute_values_sequential(data,'incentive',[-.5,.5])\n",
    "\n",
    "## direction and magnitude\n",
    "data['stim_des'] = data['stim_easy']*data['desirability'] \n",
    "\n",
    "data['resp_des'] = data['resp']*data['des_side'] #responded desirable vs undesirable (+1/-1)\n",
    "\n",
    "data = data[data['desirability']!=0] #keep only trials with desirability manipulation (for now)\n",
    "#%% Data cleaning/exclusion\n",
    "\n",
    "MIN_RT = 200 \n",
    "MAX_RT = 35000 \n",
    "MAD_THRESH_RT = 3\n",
    "\n",
    "ACC_THRESH_LO = 0.525 \n",
    "ACC_THRESH_HI = 0.975\n",
    "\n",
    "MIN_TRIALS_PER_COND = 8\n",
    "COND_VARS = ['incentive', 'desirability']\n",
    "\n",
    "#count original number of trials before exclusion\n",
    "n_trials_raw= len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92637a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(~data['correct'].isna()) & (~data['rt'].isna())\n",
    "             & (data['rt']> MIN_RT) & (data['rt'] < MAX_RT) & (~data['resp'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "024aeedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.groupby('participant')['rt'].transform(lambda x: abs(robust_z(x)))<MAD_THRESH_RT]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e055d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N trials excluded = 1066 / 19200\n",
      "Mean RT = 1734 ms, median RT = 1502 ms, max RT = 29557 ms\n"
     ]
    }
   ],
   "source": [
    "print('N trials excluded = %i / %i'%(n_trials_raw - len(data),n_trials_raw))\n",
    "\n",
    "print('Mean RT = %i ms, median RT = %i ms, max RT = %i ms' % (data['rt'].mean(),data['rt'].median(),data['rt'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f884284",
   "metadata": {},
   "source": [
    "## Participant Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4554aa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N participants kept (accuracy) = 438 / 600\n",
      "N participants kept (RT) = 427 / 438\n",
      "N participants kept after excluding participants with too few trials = 425 / 427\n"
     ]
    }
   ],
   "source": [
    "participant_accuracy = data.groupby('participant')['correct'].mean()\n",
    "valid_participants = participant_accuracy[(participant_accuracy > ACC_THRESH_LO) & (participant_accuracy < ACC_THRESH_HI)].index\n",
    "\n",
    "print('N participants kept (accuracy) = %i / %i'%(len(valid_participants),len(data['participant'].unique())))\n",
    "data = data[data['participant'].isin(valid_participants)]\n",
    "\n",
    "#remove participants with extreme median RTs compared to sample\n",
    "participant_rt = data.groupby('participant')['rt'].median()\n",
    "valid_participants_rt = participant_rt[np.abs(robust_z(participant_rt))<3].index\n",
    "print('N participants kept (RT) = %i / %i'%(len(valid_participants_rt),len(data['participant'].unique())))\n",
    "data = data[data['participant'].isin(valid_participants_rt)]\n",
    "\n",
    "# remove participants, who, after exclsion, have too few trials for one or more conditions\n",
    "groupby_vars = ['participant']\n",
    "groupby_vars.extend(COND_VARS)\n",
    "sub_trials_per_cond = data.groupby(groupby_vars).size().reset_index(name='n_trials')\n",
    "\n",
    "#get list of participants that have at least min_trials_per_cond trials per condition (combination of incentive and desirability values)\n",
    "df_participants_with_min_trials = sub_trials_per_cond.groupby('participant').filter(lambda x: (x['n_trials'] >= MIN_TRIALS_PER_COND).all())\n",
    "valid_participants = df_participants_with_min_trials['participant'].unique().tolist()\n",
    "print('N participants kept after excluding participants with too few trials = %i / %i'%(len(valid_participants),len(data['participant'].unique())))\n",
    "data = data[data['participant'].isin(valid_participants)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3c8e9e",
   "metadata": {},
   "source": [
    "## HSSM DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30fca931",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hssm = pd.DataFrame({\n",
    "    'response': data['resp_des'].astype('int32'),\n",
    "    'rt': (data['rt'] / 1000).astype('float32'),\n",
    "    'participant_id': data['participant'].astype('int32')\n",
    "})\n",
    "\n",
    "df_hssm = df_hssm.astype({col: 'float32' for col in df_hssm.select_dtypes(include='float64').columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7284274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>rt</th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.687</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.616</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>1</td>\n",
       "      <td>2.698</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>1</td>\n",
       "      <td>1.673</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>1</td>\n",
       "      <td>1.415</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.692</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12898 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       response     rt  participant_id\n",
       "0            -1  1.115               1\n",
       "1            -1  2.170               1\n",
       "2            -1  2.096               1\n",
       "3             1  1.687               1\n",
       "4             1  2.857               1\n",
       "...         ...    ...             ...\n",
       "19195        -1  2.616             600\n",
       "19196         1  2.698             600\n",
       "19197         1  1.673             600\n",
       "19198         1  1.415             600\n",
       "19199        -1  1.692             600\n",
       "\n",
       "[12898 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f399e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ids = np.random.choice(\n",
    "    df_hssm.participant_id.unique(),\n",
    "    size=round(len(df_hssm.participant_id.unique())/10),\n",
    "    replace = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bfae733",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_hssm[df_hssm['participant_id'].isin(random_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54fc2663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>rt</th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.8854</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.8173</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.2342</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.5838</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.5828</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19131</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19132</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.2660</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19133</th>\n",
       "      <td>-1</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19134</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19135</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.3640</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1282 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       response      rt  participant_id\n",
       "1760         -1  0.8854              56\n",
       "1761         -1  1.8173              56\n",
       "1762         -1  2.2342              56\n",
       "1763         -1  1.5838              56\n",
       "1765         -1  1.5828              56\n",
       "...         ...     ...             ...\n",
       "19131        -1  0.6140             598\n",
       "19132        -1  1.2660             598\n",
       "19133        -1  0.6180             598\n",
       "19134         1  1.0000             598\n",
       "19135        -1  1.3640             598\n",
       "\n",
       "[1282 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80d2d0",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdda7559",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5d82a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___Participant 56, 1/42___\n",
      "Median RT = 1.601\n",
      "N trials = 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 300 samples in chain.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [t, z, v_Intercept, a_Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3900' class='' max='3900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3900/3900 00:11&lt;00:00 Sampling 3 chains, 5 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 1_000 tune and 300 draw iterations (3_000 + 900 draws total) took 12 seconds.\n",
      "/Users/javierrojas/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:130: UserWarning: In variable a, there are more dims (1) given than exist (0). Passed array should have shape (chain,draw, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "different number of dimensions on data and dims: 2 vs 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 32\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m hssm\u001b[38;5;241m.\u001b[39mHSSM(\n\u001b[1;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mddm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     data\u001b[38;5;241m=\u001b[39mdf_sub,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     ]\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m infer_data_sub \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlog_likelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m fit_dict \u001b[38;5;241m=\u001b[39m infer_data_sub\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/hssm/hssm.py:343\u001b[0m, in \u001b[0;36mHSSM.sample\u001b[0;34m(self, sampler, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_extra_fields():\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_extra_fields()\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minference_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraces\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bambi/models.py:325\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_mean, inference_method, init, n_init, chains, cores, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_name]\n\u001b[1;32m    319\u001b[0m     _log\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModeling the probability that \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    321\u001b[0m         response\u001b[38;5;241m.\u001b[39mresponse_term\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28mstr\u001b[39m(response\u001b[38;5;241m.\u001b[39mresponse_term\u001b[38;5;241m.\u001b[39msuccess),\n\u001b[1;32m    323\u001b[0m     )\n\u001b[0;32m--> 325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momit_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bambi/backend/pymc.py:96\u001b[0m, in \u001b[0;36mPyMCModel.run\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_mean, inference_method, init, n_init, chains, cores, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# NOTE: Methods return different types of objects (idata, approximation, and dictionary)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcmc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnuts_numpyro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnuts_blackjax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 96\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_mcmc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inference_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    111\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_vi(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bambi/backend/pymc.py:172\u001b[0m, in \u001b[0;36mPyMCModel._run_mcmc\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_mean, init, n_init, chains, cores, random_seed, sampler_backend, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampler_backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcmc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m         idata \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mRuntimeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValueError: Mass matrix contains\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_exc()\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m         ):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/sampling/mcmc.py:791\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, step, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, model, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_return\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_sampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midata_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/sampling/mcmc.py:859\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    857\u001b[0m ikwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m=\u001b[39mmodel, save_warmup\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m discard_tuned_samples)\n\u001b[1;32m    858\u001b[0m ikwargs\u001b[38;5;241m.\u001b[39mupdate(idata_kwargs)\n\u001b[0;32m--> 859\u001b[0m idata \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_inference_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mikwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_convergence_checks:\n\u001b[1;32m    862\u001b[0m     warns \u001b[38;5;241m=\u001b[39m run_convergence_checks(idata, model)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/backends/arviz.py:508\u001b[0m, in \u001b[0;36mto_inference_data\u001b[0;34m(trace, prior, posterior_predictive, log_likelihood, coords, dims, sample_dims, model, save_warmup, include_transformed)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trace, InferenceData):\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInferenceDataConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposterior_predictive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposterior_predictive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_likelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_warmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_warmup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_transformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_inference_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/backends/arviz.py:427\u001b[0m, in \u001b[0;36mInferenceDataConverter.to_inference_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_inference_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    420\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert all available data to an InferenceData object.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m    Note that if groups can not be created (e.g., there is no `trace`, so\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    the `posterior` and `sample_stats` can not be extracted), then the InferenceData\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    will not have those groups.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     id_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_to_xarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_stats_to_xarray(),\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior_predictive\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_predictive_to_xarray(),\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions_to_xarray(),\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriors_to_xarray(),\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobserved_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserved_data_to_xarray(),\n\u001b[1;32m    433\u001b[0m     }\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions:\n\u001b[1;32m    435\u001b[0m         id_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions_constant_data\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstant_data_to_xarray()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:65\u001b[0m, in \u001b[0;36mrequires.__call__.<locals>.wrapped\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m((\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, prop_i) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m prop_i \u001b[38;5;129;01min\u001b[39;00m prop)):\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/backends/arviz.py:277\u001b[0m, in \u001b[0;36mInferenceDataConverter.posterior_to_xarray\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_trace:\n\u001b[1;32m    273\u001b[0m         data[var_name] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    274\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_trace\u001b[38;5;241m.\u001b[39mget_values(var_name, combine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, squeeze\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    275\u001b[0m         )\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 277\u001b[0m     \u001b[43mdict_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpymc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    284\u001b[0m     dict_to_dataset(\n\u001b[1;32m    285\u001b[0m         data_warmup,\n\u001b[1;32m    286\u001b[0m         library\u001b[38;5;241m=\u001b[39mpymc,\n\u001b[1;32m    287\u001b[0m         coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords,\n\u001b[1;32m    288\u001b[0m         dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims,\n\u001b[1;32m    289\u001b[0m         attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs,\n\u001b[1;32m    290\u001b[0m     ),\n\u001b[1;32m    291\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:306\u001b[0m, in \u001b[0;36mdict_to_dataset\u001b[0;34m(data, attrs, library, coords, dims, default_dims, index_origin, skip_event_dims)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     dims \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 306\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    307\u001b[0m     key: numpy_to_data_array(\n\u001b[1;32m    308\u001b[0m         values,\n\u001b[1;32m    309\u001b[0m         var_name\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m    310\u001b[0m         coords\u001b[38;5;241m=\u001b[39mcoords,\n\u001b[1;32m    311\u001b[0m         dims\u001b[38;5;241m=\u001b[39mdims\u001b[38;5;241m.\u001b[39mget(key),\n\u001b[1;32m    312\u001b[0m         default_dims\u001b[38;5;241m=\u001b[39mdefault_dims,\n\u001b[1;32m    313\u001b[0m         index_origin\u001b[38;5;241m=\u001b[39mindex_origin,\n\u001b[1;32m    314\u001b[0m         skip_event_dims\u001b[38;5;241m=\u001b[39mskip_event_dims,\n\u001b[1;32m    315\u001b[0m     )\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    317\u001b[0m }\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mDataset(data_vars\u001b[38;5;241m=\u001b[39mdata_vars, attrs\u001b[38;5;241m=\u001b[39mmake_attrs(attrs\u001b[38;5;241m=\u001b[39mattrs, library\u001b[38;5;241m=\u001b[39mlibrary))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:307\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     dims \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    306\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 307\u001b[0m     key: \u001b[43mnumpy_to_data_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_origin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_origin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_event_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_event_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    317\u001b[0m }\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mDataset(data_vars\u001b[38;5;241m=\u001b[39mdata_vars, attrs\u001b[38;5;241m=\u001b[39mmake_attrs(attrs\u001b[38;5;241m=\u001b[39mattrs, library\u001b[38;5;241m=\u001b[39mlibrary))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:255\u001b[0m, in \u001b[0;36mnumpy_to_data_array\u001b[0;34m(ary, var_name, coords, dims, default_dims, index_origin, skip_event_dims)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# filter coords based on the dims\u001b[39;00m\n\u001b[1;32m    254\u001b[0m coords \u001b[38;5;241m=\u001b[39m {key: xr\u001b[38;5;241m.\u001b[39mIndexVariable((key,), data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39masarray(coords[key])) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dims}\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xarray/core/dataarray.py:471\u001b[0m, in \u001b[0;36mDataArray.__init__\u001b[0;34m(self, data, coords, dims, name, attrs, indexes, fastpath)\u001b[0m\n\u001b[1;32m    469\u001b[0m data \u001b[38;5;241m=\u001b[39m _check_data_shape(data, coords, dims)\n\u001b[1;32m    470\u001b[0m data \u001b[38;5;241m=\u001b[39m as_compatible_data(data)\n\u001b[0;32m--> 471\u001b[0m coords, dims \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_coords_and_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m variable \u001b[38;5;241m=\u001b[39m Variable(dims, data, attrs, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(coords, Coordinates):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xarray/core/dataarray.py:177\u001b[0m, in \u001b[0;36m_infer_coords_and_dims\u001b[0;34m(shape, coords, dims)\u001b[0m\n\u001b[1;32m    175\u001b[0m dims_tuple \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(dims)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dims_tuple) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferent number of dimensions on data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand dims: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dims_tuple)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dims_tuple:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hashable(d):\n",
      "\u001b[0;31mValueError\u001b[0m: different number of dimensions on data and dims: 2 vs 3"
     ]
    }
   ],
   "source": [
    "for nsub, isub in enumerate(df_test['participant_id'].unique()):\n",
    "    print(f\"___Participant {isub}, {nsub+1}/{len(df_test['participant_id'].unique())}___\")\n",
    "\n",
    "    participant_folder = f\"plots/Exp4/S{int(isub):04d}\"   \n",
    "    os.makedirs(participant_folder, exist_ok=True)\n",
    "\n",
    "    df_sub = df_test[df_test['participant_id'] == isub].copy()\n",
    "    df_sub = df_sub.drop('participant_id', axis = 1)\n",
    "\n",
    "    print(\"Median RT =\", np.median(df_sub['rt']))\n",
    "    print(\"N trials =\", len(df_sub))\n",
    "\n",
    "    model = hssm.HSSM(\n",
    "        model=\"ddm\",\n",
    "        data=df_sub,\n",
    "        include=[\n",
    "            {\n",
    "                \"name\":\"v\",\n",
    "                \"formula\":\"v ~ 1\",\n",
    "                \"prior\":{\"Intercept\":{\"name\":\"Normal\",\"mu\":0,\"sigma\":1}}\n",
    "            },\n",
    "            {\n",
    "                \"name\":\"a\",\n",
    "                \"formula\":\"a ~ 1\",\n",
    "                \"prior\":{\"Intercept\":{\"name\":\"Normal\",\"mu\":1.5,\"sigma\":0.5}}\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"starting model\")\n",
    "\n",
    "    infer_data_sub = model.sample(\n",
    "        cores=3,\n",
    "        chains=3,\n",
    "        draws=300,\n",
    "        tune=1000,\n",
    "        idata_kwargs=dict(log_likelihood=False),\n",
    "        progressbar=True,\n",
    "        target_accept=0.99,\n",
    "    )\n",
    "\n",
    "    print(\"model done\")\n",
    "\n",
    "    fit_dict = infer_data_sub.to_dict()\n",
    "\n",
    "    summary_table = az.summary(infer_data_sub)\n",
    "    print(summary_table.to_string())\n",
    "    with open(os.path.join(participant_folder, \"summary_table.txt\"), \"w\") as file:\n",
    "        file.write(summary_table.to_string())\n",
    "\n",
    "        # Save plots\n",
    "    az.plot_posterior(infer_data_sub)\n",
    "    plt.savefig(os.path.join(participant_folder, \"posterior_plot.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6e2d5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Only 300 samples in chain.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (3 chains in 3 jobs)\n",
      "NUTS: [t, z, v_Intercept, a_Intercept]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='3900' class='' max='3900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [3900/3900 00:11&lt;00:00 Sampling 3 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 3 chains for 1_000 tune and 300 draw iterations (3_000 + 900 draws total) took 11 seconds.\n",
      "/Users/javierrojas/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:130: UserWarning: In variable a, there are more dims (1) given than exist (0). Passed array should have shape (chain,draw, *shape)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling returned error (or not PyMC backend). Exception: different number of dimensions on data and dims: 2 vs 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "different number of dimensions on data and dims: 2 vs 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Debug: get raw trace (no automatic to_inference_data conversion) and print shapes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     trace \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# avoid automatic pm.to_inference_data\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.99\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlog_likelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot raw trace; inspecting variable shapes...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# For PyMC MultiTrace\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/hssm/hssm.py:343\u001b[0m, in \u001b[0;36mHSSM.sample\u001b[0;34m(self, sampler, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_extra_fields():\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_extra_fields()\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minference_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraces\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bambi/models.py:325\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_mean, inference_method, init, n_init, chains, cores, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_name]\n\u001b[1;32m    319\u001b[0m     _log\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModeling the probability that \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    321\u001b[0m         response\u001b[38;5;241m.\u001b[39mresponse_term\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28mstr\u001b[39m(response\u001b[38;5;241m.\u001b[39mresponse_term\u001b[38;5;241m.\u001b[39msuccess),\n\u001b[1;32m    323\u001b[0m     )\n\u001b[0;32m--> 325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43momit_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_mean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bambi/backend/pymc.py:96\u001b[0m, in \u001b[0;36mPyMCModel.run\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_mean, inference_method, init, n_init, chains, cores, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# NOTE: Methods return different types of objects (idata, approximation, and dictionary)\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inference_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcmc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnuts_numpyro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnuts_blackjax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 96\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_mcmc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43momit_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inference_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvi\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    111\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_vi(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bambi/backend/pymc.py:172\u001b[0m, in \u001b[0;36mPyMCModel._run_mcmc\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_mean, init, n_init, chains, cores, random_seed, sampler_backend, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sampler_backend \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcmc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m         idata \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mRuntimeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    185\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValueError: Mass matrix contains\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m traceback\u001b[38;5;241m.\u001b[39mformat_exc()\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m         ):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/sampling/mcmc.py:791\u001b[0m, in \u001b[0;36msample\u001b[0;34m(draws, tune, chains, cores, random_seed, progressbar, step, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, model, **kwargs)\u001b[0m\n\u001b[1;32m    787\u001b[0m t_sampling \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t_start\n\u001b[1;32m    789\u001b[0m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sample_return\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt_sampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_sampling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiscard_tuned_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_convergence_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inferencedata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_warning_stat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43midata_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midata_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/sampling/mcmc.py:859\u001b[0m, in \u001b[0;36m_sample_return\u001b[0;34m(run, traces, tune, t_sampling, discard_tuned_samples, compute_convergence_checks, return_inferencedata, keep_warning_stat, idata_kwargs, model)\u001b[0m\n\u001b[1;32m    857\u001b[0m ikwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m=\u001b[39mmodel, save_warmup\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m discard_tuned_samples)\n\u001b[1;32m    858\u001b[0m ikwargs\u001b[38;5;241m.\u001b[39mupdate(idata_kwargs)\n\u001b[0;32m--> 859\u001b[0m idata \u001b[38;5;241m=\u001b[39m \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_inference_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mikwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_convergence_checks:\n\u001b[1;32m    862\u001b[0m     warns \u001b[38;5;241m=\u001b[39m run_convergence_checks(idata, model)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/backends/arviz.py:508\u001b[0m, in \u001b[0;36mto_inference_data\u001b[0;34m(trace, prior, posterior_predictive, log_likelihood, coords, dims, sample_dims, model, save_warmup, include_transformed)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trace, InferenceData):\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace\n\u001b[0;32m--> 508\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInferenceDataConverter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposterior_predictive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposterior_predictive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_likelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_likelihood\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_warmup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_warmup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_transformed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_inference_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/backends/arviz.py:427\u001b[0m, in \u001b[0;36mInferenceDataConverter.to_inference_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_inference_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    420\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert all available data to an InferenceData object.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m    Note that if groups can not be created (e.g., there is no `trace`, so\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    the `posterior` and `sample_stats` can not be extracted), then the InferenceData\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;124;03m    will not have those groups.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     id_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_to_xarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_stats_to_xarray(),\n\u001b[1;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior_predictive\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_predictive_to_xarray(),\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions_to_xarray(),\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriors_to_xarray(),\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobserved_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserved_data_to_xarray(),\n\u001b[1;32m    433\u001b[0m     }\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictions:\n\u001b[1;32m    435\u001b[0m         id_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions_constant_data\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstant_data_to_xarray()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:65\u001b[0m, in \u001b[0;36mrequires.__call__.<locals>.wrapped\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m((\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, prop_i) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m prop_i \u001b[38;5;129;01min\u001b[39;00m prop)):\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymc/backends/arviz.py:277\u001b[0m, in \u001b[0;36mInferenceDataConverter.posterior_to_xarray\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_trace:\n\u001b[1;32m    273\u001b[0m         data[var_name] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m    274\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposterior_trace\u001b[38;5;241m.\u001b[39mget_values(var_name, combine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, squeeze\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    275\u001b[0m         )\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 277\u001b[0m     \u001b[43mdict_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpymc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    284\u001b[0m     dict_to_dataset(\n\u001b[1;32m    285\u001b[0m         data_warmup,\n\u001b[1;32m    286\u001b[0m         library\u001b[38;5;241m=\u001b[39mpymc,\n\u001b[1;32m    287\u001b[0m         coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoords,\n\u001b[1;32m    288\u001b[0m         dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims,\n\u001b[1;32m    289\u001b[0m         attrs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs,\n\u001b[1;32m    290\u001b[0m     ),\n\u001b[1;32m    291\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:306\u001b[0m, in \u001b[0;36mdict_to_dataset\u001b[0;34m(data, attrs, library, coords, dims, default_dims, index_origin, skip_event_dims)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     dims \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 306\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    307\u001b[0m     key: numpy_to_data_array(\n\u001b[1;32m    308\u001b[0m         values,\n\u001b[1;32m    309\u001b[0m         var_name\u001b[38;5;241m=\u001b[39mkey,\n\u001b[1;32m    310\u001b[0m         coords\u001b[38;5;241m=\u001b[39mcoords,\n\u001b[1;32m    311\u001b[0m         dims\u001b[38;5;241m=\u001b[39mdims\u001b[38;5;241m.\u001b[39mget(key),\n\u001b[1;32m    312\u001b[0m         default_dims\u001b[38;5;241m=\u001b[39mdefault_dims,\n\u001b[1;32m    313\u001b[0m         index_origin\u001b[38;5;241m=\u001b[39mindex_origin,\n\u001b[1;32m    314\u001b[0m         skip_event_dims\u001b[38;5;241m=\u001b[39mskip_event_dims,\n\u001b[1;32m    315\u001b[0m     )\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    317\u001b[0m }\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mDataset(data_vars\u001b[38;5;241m=\u001b[39mdata_vars, attrs\u001b[38;5;241m=\u001b[39mmake_attrs(attrs\u001b[38;5;241m=\u001b[39mattrs, library\u001b[38;5;241m=\u001b[39mlibrary))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:307\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     dims \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    306\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 307\u001b[0m     key: \u001b[43mnumpy_to_data_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdefault_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_origin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_origin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_event_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_event_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    317\u001b[0m }\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mDataset(data_vars\u001b[38;5;241m=\u001b[39mdata_vars, attrs\u001b[38;5;241m=\u001b[39mmake_attrs(attrs\u001b[38;5;241m=\u001b[39mattrs, library\u001b[38;5;241m=\u001b[39mlibrary))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/arviz/data/base.py:255\u001b[0m, in \u001b[0;36mnumpy_to_data_array\u001b[0;34m(ary, var_name, coords, dims, default_dims, index_origin, skip_event_dims)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# filter coords based on the dims\u001b[39;00m\n\u001b[1;32m    254\u001b[0m coords \u001b[38;5;241m=\u001b[39m {key: xr\u001b[38;5;241m.\u001b[39mIndexVariable((key,), data\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39masarray(coords[key])) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dims}\n\u001b[0;32m--> 255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xarray/core/dataarray.py:471\u001b[0m, in \u001b[0;36mDataArray.__init__\u001b[0;34m(self, data, coords, dims, name, attrs, indexes, fastpath)\u001b[0m\n\u001b[1;32m    469\u001b[0m data \u001b[38;5;241m=\u001b[39m _check_data_shape(data, coords, dims)\n\u001b[1;32m    470\u001b[0m data \u001b[38;5;241m=\u001b[39m as_compatible_data(data)\n\u001b[0;32m--> 471\u001b[0m coords, dims \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_coords_and_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m variable \u001b[38;5;241m=\u001b[39m Variable(dims, data, attrs, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(coords, Coordinates):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/xarray/core/dataarray.py:177\u001b[0m, in \u001b[0;36m_infer_coords_and_dims\u001b[0;34m(shape, coords, dims)\u001b[0m\n\u001b[1;32m    175\u001b[0m dims_tuple \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(dims)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dims_tuple) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferent number of dimensions on data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand dims: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dims_tuple)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m     )\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dims_tuple:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hashable(d):\n",
      "\u001b[0;31mValueError\u001b[0m: different number of dimensions on data and dims: 2 vs 3"
     ]
    }
   ],
   "source": [
    "# Debug: get raw trace (no automatic to_inference_data conversion) and print shapes\n",
    "try:\n",
    "    trace = model.sample(\n",
    "        cores=3, chains=3, draws=300, tune=1000,\n",
    "        return_inferencedata=False,  # avoid automatic pm.to_inference_data\n",
    "        progressbar=True, target_accept=0.99,\n",
    "        idata_kwargs=dict(log_likelihood=False),\n",
    "    )\n",
    "    print(\"Got raw trace; inspecting variable shapes...\")\n",
    "    # For PyMC MultiTrace\n",
    "    varnames = [v for v in trace.varnames if not v.endswith(\"__\")]\n",
    "    for v in varnames:\n",
    "        arr = trace.get_values(v, combine=False, squeeze=False)  # list per chain\n",
    "        # convert to ndarray with chain dimension first\n",
    "        arr = np.asarray(arr)  # shape: (n_chains, n_draws, *event_shape)\n",
    "        print(v, \"-> shape:\", arr.shape, \"ndim:\", arr.ndim)\n",
    "except Exception as e:\n",
    "    print(\"Sampling returned error (or not PyMC backend). Exception:\", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeeb2635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ae01b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bbead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395688d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Base folder containing participant subfolders\n",
    "base_folder = \"plots/Exp4\"\n",
    "\n",
    "all_summaries = []\n",
    "\n",
    "# Find all summary_table.txt files recursively\n",
    "txt_files = glob.glob(os.path.join(base_folder, \"S*\", \"summary_table.txt\"))\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    # Extract participant id from folder name\n",
    "    participant_id = int(os.path.basename(os.path.dirname(txt_file))[1:])  # 'S0001' -> 1\n",
    "    \n",
    "    # Read the txt table\n",
    "    try:\n",
    "        df = pd.read_csv(txt_file, delim_whitespace=True, index_col=0)\n",
    "    except pd.errors.ParserError:\n",
    "        # fallback if the txt is formatted as a print(table)\n",
    "        df = pd.read_fwf(txt_file, index_col=0)\n",
    "    \n",
    "    df['participant_id'] = participant_id\n",
    "    all_summaries.append(df.reset_index().rename(columns={'index':'param'}))\n",
    "\n",
    "# Concatenate all participants into a single DataFrame\n",
    "df_all = pd.concat(all_summaries, ignore_index=True)\n",
    "\n",
    "print(df_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc82d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v = df_all[df_all['param']=='v_Intercept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22203b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df_v['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter for drift rate (v_Intercept)\n",
    "df_v = df_all[df_all['param'] == 'v_Intercept']\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(df_v['mean'], fill=True, bw_adjust=0.5)\n",
    "sns.rugplot(df_v['mean'], color='k')\n",
    "plt.xlabel(\"Drift rate (v_Intercept)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of fitted drift rates across participants\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_summary = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf626452",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(all_summary, ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
